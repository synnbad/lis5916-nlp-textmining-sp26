{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6876b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9bfe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a155920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"In 1950, Alan Turing published his famous article 'Computing Machinery and Intelligence' which proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge, sufficiently well that the judge is unable to distinguish reliably â€” on the basis of the conversational content alone â€” between the program and a real human. In 1957, Noam Chomskyâ€™s Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule-based system of syntactic structures.The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, which found that ten years long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed. Some notably successful NLP systems developed in the 1960s were SHRDLU, a natural language system working in restricted 'blocks worlds' with restricted vocabularies. In 1969 Roger Schank introduced the conceptual dependency theory for natural language understanding.This model, partially influenced by the work of Sydney Lamb, was extensively used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner. In 1970, William A. Woods introduced the augmented transition network (ATN) to represent natural language input. Instead of phrase structure rules ATNs used an equivalent set of finite-state automata that were called recursively. ATNs and their more general format called 'generalized ATNs' continued to be used for a number of years. During the 1970s many programmers began to write 'conceptual ontologies', which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky. In recent years, advancements in deep learning and large language models have significantly enhanced the capabilities of natural language processing, leading to widespread applications in areas such as healthcare, customer service, and content generation.\")\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36dada5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Alan Turing', 'his famous article', 'Computing Machinery', 'Intelligence', 'which', 'what', 'the Turing test', 'a criterion', 'intelligence', 'This criterion', 'the ability', 'a computer program', 'a human', 'a real-time written conversation', 'a human judge', 'the judge', 'the basis', 'the conversational content', 'the program', 'a real human', 'Noam Chomskyâ€™s Syntactic Structures', 'Linguistics', 'universal grammar', 'a rule-based system', 'syntactic structures', 'The Georgetown experiment', 'fully automatic translation', 'more than sixty Russian sentences', 'English', 'The authors', 'three or five years', 'machine translation', 'a solved problem', 'real progress', 'the ALPAC report', 'which', 'ten years long research', 'the expectations', 'funding', 'machine translation', 'Little further research', 'machine translation', 'the late 1980s', 'the first statistical machine translation systems', 'Some notably successful NLP systems', 'the 1960s', 'a natural language system', \"restricted 'blocks worlds\", 'restricted vocabularies', 'Roger Schank', 'the conceptual dependency theory', 'natural language understanding', 'This model', 'the work', 'Sydney Lamb', \"Schank's students\", 'Yale University', 'Robert Wilensky', 'Wendy Lehnert', 'Janet Kolodner', 'William A. Woods', 'the augmented transition network', 'ATN', 'natural language input', 'phrase', 'an equivalent set', 'finite-state automata', 'that', 'ATNs', 'their more general format', \"'generalized ATNs\", 'a number', 'years', 'the 1970s', 'many programmers', 'conceptual ontologies', 'which', 'real-world information', 'computer-understandable data', 'Examples', 'MARGIE', 'Schank', 'Cullingford', 'PAM', '(Wilensky', 'TaleSpin', 'Meehan', 'QUALM', 'Lehnert', 'Politics', 'Carbonell', 'Plot Units', 'Lehnert', 'this time', 'many chatterbots', 'PARRY', 'Racter', 'Jabberwacky', 'recent years', 'advancements', 'deep learning', 'large language models', 'the capabilities', 'natural language processing', 'widespread applications', 'areas', 'healthcare', 'customer service', 'content generation']\n",
      "Verbs: ['publish', 'propose', 'call', 'ture', 'depend', 'impersonate', 'write', 'distinguish', 'revolutionize', 'base', 'involve', 'claim', 'find', 'fail', 'fulfill', 'reduce', 'conduct', 'develop', 'develop', 'work', 'restrict', 'introduce', 'influence', 'use', 'introduce', 'represent', 'rule', 'use', 'call', 'call', 'generalize', 'continue', 'use', 'begin', 'write', 'structure', 'write', 'include', 'enhance', 'lead']\n",
      "Adjectives: ['famous', 'real', 'human', 'unable', 'conversational', 'alone', 'real', 'universal', 'syntactic', 'automatic', 'more', 'russian', 'solved', 'real', 'slow', 'long', 'little', 'further', 'late', 'first', 'statistical', 'successful', 'shrdlu', 'natural', 'restricted', 'conceptual', 'natural', 'such', 'augmented', 'natural', 'equivalent', 'finite', 'general', 'many', 'conceptual', 'real', 'understandable', 'many', 'recent', 'deep', 'large', 'natural', 'widespread', 'such']\n",
      "1950 DATE\n",
      "Alan Turing PERSON\n",
      "Computing Machinery PERSON\n",
      "Intelligence ORG\n",
      "Turing ORG\n",
      "1957 DATE\n",
      "Noam Chomskyâ€ ORG\n",
      "Syntactic Structures ORG\n",
      "Linguistics PERSON\n",
      "Georgetown ORG\n",
      "1954 DATE\n",
      "more than sixty CARDINAL\n",
      "Russian NORP\n",
      "English LANGUAGE\n",
      "three or five years DATE\n",
      "ALPAC ORG\n",
      "1966 DATE\n",
      "ten years DATE\n",
      "the late 1980s DATE\n",
      "first ORDINAL\n",
      "NLP ORG\n",
      "the 1960s DATE\n",
      "SHRDLU ORG\n",
      "1969 DATE\n",
      "Roger Schank PERSON\n",
      "Sydney Lamb PERSON\n",
      "Schank PERSON\n",
      "Yale University ORG\n",
      "Robert Wilensky PERSON\n",
      "Wendy Lehnert PERSON\n",
      "Janet Kolodner PERSON\n",
      "1970 DATE\n",
      "William A. Woods PERSON\n",
      "ATN ORG\n",
      "a number of years DATE\n",
      "the 1970s DATE\n",
      "1975 DATE\n",
      "SAM PERSON\n",
      "Cullingford GPE\n",
      "1978 DATE\n",
      "PAM ORG\n",
      "Wilensky PERSON\n",
      "1978 DATE\n",
      "TaleSpin PRODUCT\n",
      "1976 DATE\n",
      "QUALM PERSON\n",
      "Lehnert PERSON\n",
      "1977 DATE\n",
      "Carbonell PERSON\n",
      "1979 DATE\n",
      "Plot Units ORG\n",
      "Lehnert PERSON\n",
      "1981 DATE\n",
      "PARRY ORG\n",
      "Jabberwacky PERSON\n",
      "recent years DATE\n",
      "Alan Turing PERSON\n",
      "Computing Machinery PERSON\n",
      "Linguistics PERSON\n",
      "Roger Schank PERSON\n",
      "Sydney Lamb PERSON\n",
      "Schank PERSON\n",
      "Robert Wilensky PERSON\n",
      "Wendy Lehnert PERSON\n",
      "Janet Kolodner PERSON\n",
      "William A. Woods PERSON\n",
      "SAM PERSON\n",
      "Wilensky PERSON\n",
      "QUALM PERSON\n",
      "Lehnert PERSON\n",
      "Carbonell PERSON\n",
      "Lehnert PERSON\n",
      "Jabberwacky PERSON\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"Adjectives:\", [token.lemma_ for token in doc if token.pos_ == \"ADJ\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n",
    "\n",
    "# Find named enitities relating to animals\n",
    "for entity in doc.ents:\n",
    "    if entity.label_ == \"PERSON\":\n",
    "        print(entity.text, entity.label_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5edf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Entity Labels: ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# List all entity labels available in the 'ner' pipeline\n",
    "print(\"Available Entity Labels:\", nlp.pipe_labels['ner'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
